{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data mining from PubChem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import os \n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "import time\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "from Bio.PDB import *\n",
    "import os, shutil\n",
    "from biopandas.pdb import PandasPdb\n",
    "from Bio import ExPASy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Query sent to NCBIWWW against swissprot database\n",
      "Top hits: ['P69834', 'Q5N8G1', 'Q6MEE8']\n",
      "Target not found in database\n",
      "Target not found in database\n",
      "Entry P69834 present in database!\n"
     ]
    }
   ],
   "source": [
    "# protein_query = \"MAMLQTNLGFITSPTFLCPKLKVKLNSYLWFSYRSQVQKLDFSKRVNRSYKRDALLLSIKCSSSTGFDNSNVVVKEKSVSVILLAGGQGKRMKMSMPKQYIPLLGQPIALYSFFTFSRMPEVKEIVVVCDPFFRDIFEEYEESIDVDLRFAIPGKERQDSVYSGLQEIDVNSELVCIHDSARPLVNTEDVEKVLKDGSAVGAAVLGVPAKATIKEVNSDSLVVKTLDRKTLWEMQTPQVIKPELLKKGFELVKSEGLEVTDDVSIVEYLKHPVYVSQGSYTNIKVTTPDDLLLAERILSEDS\"\n",
    "\n",
    "# nucleotide_query = \"ATGGCGATGCTTCAGACGAATCTTGGCTTCATTACTTCTCCGACATTTCTGTGTCCGAAGCTTAAAGTCAAATTGAACTCTTATCTGTGGTTTAGCTATCGTTCTCAAGTTCAAAAACTGGATTTTTCGAAAAGGGTTAATAGAAGCTACAAAAGAGATGCTTTATTATTGTCAATCAAGTGTTCTTCATCGACTGGATTTGATAATAGCAATGTTGTTGTGAAGGAGAAGAGTGTATCTGTGATTCTTTTAGCTGGAGGTCAAGGCAAGAGAATGAAAATGAGTATGCCAAAGCAGTACATACCACTTCTTGGTCAGCCAATTGCTTTGTATAGCTTTTTCACGTTTTCACGTATGCCTGAAGTGAAGGAAATTGTAGTTGTATGTGATCCTTTTTTCAGAGACATTTTTGAAGAATACGAAGAATCAATTGATGTTGATCTTAGATTCGCTATTCCTGGCAAAGAAAGACAAGATTCTGTTTACAGTGGACTTCAGGAAATCGATGTGAACTCTGAGCTTGTTTGTATCCACGACTCTGCCCGACCATTGGTGAATACTGAAGATGTCGAGAAGGTCCTTAAAGATGGTTCCGCGGTTGGAGCAGCTGTACTTGGTGTTCCTGCTAAAGCTACAATCAAAGAGGTCAATTCTGATTCGCTTGTGGTGAAAACTCTCGACAGAAAAACCCTATGGGAAATGCAGACACCACAGGTGATCAAACCAGAGCTATTGAAAAAGGGTTTCGAGCTTGTAAAAAGTGAAGGTCTAGAGGTAACAGATGACGTTTCGATTGTTGAATACCTCAAGCATCCAGTTTATGTCTCTCAAGGATCTTATACAAACATCAAGGTTACAACACCTGATGATTTACTGCTTGCTGAGAGAATCTTGAGCGAGGACTCATGA\"\n",
    "\n",
    "query = Seq(input(\"Paste input in a form of FASTA sequence: \"))\n",
    "\n",
    "# def blast_input():\n",
    "# my_query = Seq(nucleotide_query)\n",
    "# query = SeqIO.read(\"sample.fasta\", format=\"fasta\")\n",
    "try:\n",
    "    print(\"Query sent to NCBIWWW against swissprot database\")\n",
    "    result_handle = NCBIWWW.qblast(\"blastp\", \"swissprot\", query)\n",
    "    blast_result = open(\"my_blast_result.xml\", \"w\")\n",
    "    blast_result.write(result_handle.read())\n",
    "    blast_result.close()\n",
    "    result_handle.close()\n",
    "except ValueError:\n",
    "    my_translated_query = my_query.translate()\n",
    "    print(f\"DNA/RNA sequence detected. Sequence translated to : {my_translated_query}\")\n",
    "    result_handle = NCBIWWW.qblast(\"blastp\", \"swissprot\", my_translated_query)\n",
    "    blast_result = open(\"my_blast_result.xml\", \"w\")\n",
    "    blast_result.write(result_handle.read())\n",
    "    blast_result.close()\n",
    "    result_handle.close()\n",
    "\n",
    "\n",
    "# def read_blast_output():\n",
    "result = open(\"my_blast_result.xml\")\n",
    "blast_records = NCBIXML.parse(result)\n",
    "number_of_alignments = 0\n",
    "hit_ids = []\n",
    "for rec in blast_records:\n",
    "    for alignment in rec.alignments:\n",
    "        hit_ids.append(alignment.accession)\n",
    "        number_of_alignments += 1\n",
    "        if number_of_alignments == 3: # Take three top alignments and stop\n",
    "            break\n",
    "print(f\"Top hits: {hit_ids}\")\n",
    "# return hit_ids\n",
    "if len(hit_ids) == 0:\n",
    "    print(\"No hits identified in the database. Check your FASTA input.\")\n",
    "# def read_target_db(input_list: list):\n",
    "with open('target', 'r') as df:\n",
    "    for line in df:\n",
    "        line = line.split()\n",
    "        try:\n",
    "            for entry in hit_ids:\n",
    "                if entry in line[2]:\n",
    "                    print(f\"Entry {entry} present in database!\")\n",
    "                    check_id = entry\n",
    "                    break\n",
    "        except:\n",
    "            print(\"Target not found in database\")\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     blast_input()\n",
    "#     read_target_db(read_blast_output())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = \"https://pubchem.ncbi.nlm.nih.gov/sdq/sdqagent.cgi?infmt=json&outfmt=csv&query={%22download%22:%22*%22,%22collection%22:%22bioactivity%22,%22where%22:{%22ands%22:[{%22protacxn%22:%22notnull%22},{%22cid%22:%22notnull%22},{%22repacxn%22:%22P0C6U8%22}]},%22order%22:[%22activity,asc%22],%22start%22:1,%22limit%22:10000000,%22downloadfilename%22:%22{PROTACXN_P0C6U8}_bioactivity_protein%22}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pubchem.ncbi.nlm.nih.gov/sdq/sdqagent.cgi?infmt=json&outfmt=csv&query={%22download%22:%22*%22,%22collection%22:%22bioactivity%22,%22where%22:{%22ands%22:[{%22protacxn%22:%22notnull%22},{%22cid%22:%22notnull%22},{%22repacxn%22:%22P0C6U8%22}]},%22order%22:[%22activity,asc%22],%22start%22:1,%22limit%22:10000000,%22downloadfilename%22:%22{P69834}_bioactivity_protein%22}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link1 = link1.replace('PROTACXN_P0C6U8', check_id)\n",
    "link1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2):\n",
    "    try:\n",
    "        os.remove('downloaded1.csv')\n",
    "        #print(\"Deleted old File\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        #print(\"No file \")\n",
    "        break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    try:\n",
    "        data = pd.read_csv(link1)\n",
    "        break\n",
    "    #except IncompleteRead as I:\n",
    "     #   print(\"Server Overloading , Proceeding\")\n",
    "      #  break\n",
    "    except Exception as a:\n",
    "        print(str(a)+\" is the error , Trying {} time\".format(i))\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "else:\n",
    "    print(\"something Wrong , Try running Again [refer error code for more]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"downloaded1.csv\",error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baid</th>\n",
       "      <th>activity</th>\n",
       "      <th>aid</th>\n",
       "      <th>sid</th>\n",
       "      <th>mid</th>\n",
       "      <th>cid</th>\n",
       "      <th>geneid</th>\n",
       "      <th>taxid</th>\n",
       "      <th>pmid</th>\n",
       "      <th>aidtype</th>\n",
       "      <th>...</th>\n",
       "      <th>acname</th>\n",
       "      <th>acvalue</th>\n",
       "      <th>aidsrcname</th>\n",
       "      <th>aidname</th>\n",
       "      <th>cmpdname</th>\n",
       "      <th>targetname</th>\n",
       "      <th>targeturl</th>\n",
       "      <th>dois</th>\n",
       "      <th>ecs</th>\n",
       "      <th>repacxn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98754968</td>\n",
       "      <td>Active</td>\n",
       "      <td>241511</td>\n",
       "      <td>103458247</td>\n",
       "      <td>0</td>\n",
       "      <td>11667869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227859</td>\n",
       "      <td>15896959</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>...</td>\n",
       "      <td>IC50</td>\n",
       "      <td>0.98</td>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>In vitro inhibitory concentration SARS coronav...</td>\n",
       "      <td>1-Benzo[b]thiophen-2-ylmethyl-7-bromo-1H-indol...</td>\n",
       "      <td>Replicase polyprotein 1a (SARS coronavirus)</td>\n",
       "      <td>/protein/P0C6U8</td>\n",
       "      <td>10.1016/j.bmcl.2005.04.027</td>\n",
       "      <td>3.4.19.12,3.4.22.-,3.4.22.69</td>\n",
       "      <td>P0C6U8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98758767</td>\n",
       "      <td>Active</td>\n",
       "      <td>241749</td>\n",
       "      <td>103458062</td>\n",
       "      <td>0</td>\n",
       "      <td>44398002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227859</td>\n",
       "      <td>15896959</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>...</td>\n",
       "      <td>IC50</td>\n",
       "      <td>9.40</td>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>In vitro inhibitory concentration against SARS...</td>\n",
       "      <td>1-(2-Chloro-4-fluoro-benzyl)-5-iodo-1H-indole-...</td>\n",
       "      <td>Replicase polyprotein 1a (SARS coronavirus)</td>\n",
       "      <td>/protein/P0C6U8</td>\n",
       "      <td>10.1016/j.bmcl.2005.04.027</td>\n",
       "      <td>3.4.19.12,3.4.22.-,3.4.22.69</td>\n",
       "      <td>P0C6U8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98758768</td>\n",
       "      <td>Active</td>\n",
       "      <td>241749</td>\n",
       "      <td>103458580</td>\n",
       "      <td>0</td>\n",
       "      <td>44398207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227859</td>\n",
       "      <td>15896959</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>...</td>\n",
       "      <td>IC50</td>\n",
       "      <td>4.82</td>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>In vitro inhibitory concentration against SARS...</td>\n",
       "      <td>1-Benzo[b]thiophen-2-ylmethyl-5-fluoro-1H-indo...</td>\n",
       "      <td>Replicase polyprotein 1a (SARS coronavirus)</td>\n",
       "      <td>/protein/P0C6U8</td>\n",
       "      <td>10.1016/j.bmcl.2005.04.027</td>\n",
       "      <td>3.4.19.12,3.4.22.-,3.4.22.69</td>\n",
       "      <td>P0C6U8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98758769</td>\n",
       "      <td>Active</td>\n",
       "      <td>241749</td>\n",
       "      <td>103458848</td>\n",
       "      <td>0</td>\n",
       "      <td>44398343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227859</td>\n",
       "      <td>15896959</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>...</td>\n",
       "      <td>IC50</td>\n",
       "      <td>2.00</td>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>In vitro inhibitory concentration against SARS...</td>\n",
       "      <td>1-Benzo[b]thiophen-2-ylmethyl-7-nitro-1H-indol...</td>\n",
       "      <td>Replicase polyprotein 1a (SARS coronavirus)</td>\n",
       "      <td>/protein/P0C6U8</td>\n",
       "      <td>10.1016/j.bmcl.2005.04.027</td>\n",
       "      <td>3.4.19.12,3.4.22.-,3.4.22.69</td>\n",
       "      <td>P0C6U8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98758770</td>\n",
       "      <td>Active</td>\n",
       "      <td>241749</td>\n",
       "      <td>103459046</td>\n",
       "      <td>0</td>\n",
       "      <td>44398436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227859</td>\n",
       "      <td>15896959</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>...</td>\n",
       "      <td>IC50</td>\n",
       "      <td>17.50</td>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>In vitro inhibitory concentration against SARS...</td>\n",
       "      <td>5-Iodo-1-[[5-(piperidine-1-carbonyl)thiophen-2...</td>\n",
       "      <td>Replicase polyprotein 1a (SARS coronavirus)</td>\n",
       "      <td>/protein/P0C6U8</td>\n",
       "      <td>10.1016/j.bmcl.2005.04.027</td>\n",
       "      <td>3.4.19.12,3.4.22.-,3.4.22.69</td>\n",
       "      <td>P0C6U8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>424668663</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>688306</td>\n",
       "      <td>163312872</td>\n",
       "      <td>0</td>\n",
       "      <td>14610613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227859</td>\n",
       "      <td>22884354</td>\n",
       "      <td>Literature-derived</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>Time dependent inhibition of SARS-CoV PLpro ex...</td>\n",
       "      <td>Methyl tanshinonate</td>\n",
       "      <td>Replicase polyprotein 1a (SARS coronavirus)</td>\n",
       "      <td>/protein/P0C6U8</td>\n",
       "      <td>10.1016/j.bmc.2012.07.038</td>\n",
       "      <td>3.4.19.12,3.4.22.-,3.4.22.69</td>\n",
       "      <td>P0C6U8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>424668664</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>688306</td>\n",
       "      <td>103456666</td>\n",
       "      <td>0</td>\n",
       "      <td>164676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227859</td>\n",
       "      <td>22884354</td>\n",
       "      <td>Literature-derived</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>Time dependent inhibition of SARS-CoV PLpro ex...</td>\n",
       "      <td>Tanshinone IIA</td>\n",
       "      <td>Replicase polyprotein 1a (SARS coronavirus)</td>\n",
       "      <td>/protein/P0C6U8</td>\n",
       "      <td>10.1016/j.bmc.2012.07.038</td>\n",
       "      <td>3.4.19.12,3.4.22.-,3.4.22.69</td>\n",
       "      <td>P0C6U8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>424668665</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>688306</td>\n",
       "      <td>103521465</td>\n",
       "      <td>0</td>\n",
       "      <td>11425923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227859</td>\n",
       "      <td>22884354</td>\n",
       "      <td>Literature-derived</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>Time dependent inhibition of SARS-CoV PLpro ex...</td>\n",
       "      <td>Dihydrotanshinone I</td>\n",
       "      <td>Replicase polyprotein 1a (SARS coronavirus)</td>\n",
       "      <td>/protein/P0C6U8</td>\n",
       "      <td>10.1016/j.bmc.2012.07.038</td>\n",
       "      <td>3.4.19.12,3.4.22.-,3.4.22.69</td>\n",
       "      <td>P0C6U8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>424668696</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>688308</td>\n",
       "      <td>103227294</td>\n",
       "      <td>0</td>\n",
       "      <td>160142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227859</td>\n",
       "      <td>22884354</td>\n",
       "      <td>Confirmatory</td>\n",
       "      <td>...</td>\n",
       "      <td>IC50</td>\n",
       "      <td>78.90</td>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>Inhibition of SARS-CoV PLpro expressed in Esch...</td>\n",
       "      <td>Miltirone</td>\n",
       "      <td>Replicase polyprotein 1a (SARS coronavirus)</td>\n",
       "      <td>/protein/P0C6U8</td>\n",
       "      <td>10.1016/j.bmc.2012.07.038</td>\n",
       "      <td>3.4.19.12,3.4.22.-,3.4.22.69</td>\n",
       "      <td>P0C6U8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>424668702</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>688309</td>\n",
       "      <td>103456480</td>\n",
       "      <td>0</td>\n",
       "      <td>160254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227859</td>\n",
       "      <td>22884354</td>\n",
       "      <td>Literature-derived</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ChEMBL</td>\n",
       "      <td>Inhibition of SARS-CoV PLpro expressed in Esch...</td>\n",
       "      <td>Cryptotanshinone</td>\n",
       "      <td>Replicase polyprotein 1a (SARS coronavirus)</td>\n",
       "      <td>/protein/P0C6U8</td>\n",
       "      <td>10.1016/j.bmc.2012.07.038</td>\n",
       "      <td>3.4.19.12,3.4.22.-,3.4.22.69</td>\n",
       "      <td>P0C6U8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          baid     activity     aid        sid  mid       cid  geneid   taxid  \\\n",
       "0     98754968       Active  241511  103458247    0  11667869     NaN  227859   \n",
       "1     98758767       Active  241749  103458062    0  44398002     NaN  227859   \n",
       "2     98758768       Active  241749  103458580    0  44398207     NaN  227859   \n",
       "3     98758769       Active  241749  103458848    0  44398343     NaN  227859   \n",
       "4     98758770       Active  241749  103459046    0  44398436     NaN  227859   \n",
       "..         ...          ...     ...        ...  ...       ...     ...     ...   \n",
       "336  424668663  Unspecified  688306  163312872    0  14610613     NaN  227859   \n",
       "337  424668664  Unspecified  688306  103456666    0    164676     NaN  227859   \n",
       "338  424668665  Unspecified  688306  103521465    0  11425923     NaN  227859   \n",
       "339  424668696  Unspecified  688308  103227294    0    160142     NaN  227859   \n",
       "340  424668702  Unspecified  688309  103456480    0    160254     NaN  227859   \n",
       "\n",
       "         pmid             aidtype  ...  acname  acvalue  aidsrcname  \\\n",
       "0    15896959        Confirmatory  ...    IC50     0.98      ChEMBL   \n",
       "1    15896959        Confirmatory  ...    IC50     9.40      ChEMBL   \n",
       "2    15896959        Confirmatory  ...    IC50     4.82      ChEMBL   \n",
       "3    15896959        Confirmatory  ...    IC50     2.00      ChEMBL   \n",
       "4    15896959        Confirmatory  ...    IC50    17.50      ChEMBL   \n",
       "..        ...                 ...  ...     ...      ...         ...   \n",
       "336  22884354  Literature-derived  ...     NaN      NaN      ChEMBL   \n",
       "337  22884354  Literature-derived  ...     NaN      NaN      ChEMBL   \n",
       "338  22884354  Literature-derived  ...     NaN      NaN      ChEMBL   \n",
       "339  22884354        Confirmatory  ...    IC50    78.90      ChEMBL   \n",
       "340  22884354  Literature-derived  ...     NaN      NaN      ChEMBL   \n",
       "\n",
       "                                               aidname  \\\n",
       "0    In vitro inhibitory concentration SARS coronav...   \n",
       "1    In vitro inhibitory concentration against SARS...   \n",
       "2    In vitro inhibitory concentration against SARS...   \n",
       "3    In vitro inhibitory concentration against SARS...   \n",
       "4    In vitro inhibitory concentration against SARS...   \n",
       "..                                                 ...   \n",
       "336  Time dependent inhibition of SARS-CoV PLpro ex...   \n",
       "337  Time dependent inhibition of SARS-CoV PLpro ex...   \n",
       "338  Time dependent inhibition of SARS-CoV PLpro ex...   \n",
       "339  Inhibition of SARS-CoV PLpro expressed in Esch...   \n",
       "340  Inhibition of SARS-CoV PLpro expressed in Esch...   \n",
       "\n",
       "                                              cmpdname  \\\n",
       "0    1-Benzo[b]thiophen-2-ylmethyl-7-bromo-1H-indol...   \n",
       "1    1-(2-Chloro-4-fluoro-benzyl)-5-iodo-1H-indole-...   \n",
       "2    1-Benzo[b]thiophen-2-ylmethyl-5-fluoro-1H-indo...   \n",
       "3    1-Benzo[b]thiophen-2-ylmethyl-7-nitro-1H-indol...   \n",
       "4    5-Iodo-1-[[5-(piperidine-1-carbonyl)thiophen-2...   \n",
       "..                                                 ...   \n",
       "336                                Methyl tanshinonate   \n",
       "337                                     Tanshinone IIA   \n",
       "338                                Dihydrotanshinone I   \n",
       "339                                          Miltirone   \n",
       "340                                   Cryptotanshinone   \n",
       "\n",
       "                                      targetname        targeturl  \\\n",
       "0    Replicase polyprotein 1a (SARS coronavirus)  /protein/P0C6U8   \n",
       "1    Replicase polyprotein 1a (SARS coronavirus)  /protein/P0C6U8   \n",
       "2    Replicase polyprotein 1a (SARS coronavirus)  /protein/P0C6U8   \n",
       "3    Replicase polyprotein 1a (SARS coronavirus)  /protein/P0C6U8   \n",
       "4    Replicase polyprotein 1a (SARS coronavirus)  /protein/P0C6U8   \n",
       "..                                           ...              ...   \n",
       "336  Replicase polyprotein 1a (SARS coronavirus)  /protein/P0C6U8   \n",
       "337  Replicase polyprotein 1a (SARS coronavirus)  /protein/P0C6U8   \n",
       "338  Replicase polyprotein 1a (SARS coronavirus)  /protein/P0C6U8   \n",
       "339  Replicase polyprotein 1a (SARS coronavirus)  /protein/P0C6U8   \n",
       "340  Replicase polyprotein 1a (SARS coronavirus)  /protein/P0C6U8   \n",
       "\n",
       "                           dois                           ecs repacxn  \n",
       "0    10.1016/j.bmcl.2005.04.027  3.4.19.12,3.4.22.-,3.4.22.69  P0C6U8  \n",
       "1    10.1016/j.bmcl.2005.04.027  3.4.19.12,3.4.22.-,3.4.22.69  P0C6U8  \n",
       "2    10.1016/j.bmcl.2005.04.027  3.4.19.12,3.4.22.-,3.4.22.69  P0C6U8  \n",
       "3    10.1016/j.bmcl.2005.04.027  3.4.19.12,3.4.22.-,3.4.22.69  P0C6U8  \n",
       "4    10.1016/j.bmcl.2005.04.027  3.4.19.12,3.4.22.-,3.4.22.69  P0C6U8  \n",
       "..                          ...                           ...     ...  \n",
       "336   10.1016/j.bmc.2012.07.038  3.4.19.12,3.4.22.-,3.4.22.69  P0C6U8  \n",
       "337   10.1016/j.bmc.2012.07.038  3.4.19.12,3.4.22.-,3.4.22.69  P0C6U8  \n",
       "338   10.1016/j.bmc.2012.07.038  3.4.19.12,3.4.22.-,3.4.22.69  P0C6U8  \n",
       "339   10.1016/j.bmc.2012.07.038  3.4.19.12,3.4.22.-,3.4.22.69  P0C6U8  \n",
       "340   10.1016/j.bmc.2012.07.038  3.4.19.12,3.4.22.-,3.4.22.69  P0C6U8  \n",
       "\n",
       "[341 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning up\n",
    "new_data = data[['cid','acvalue']]\n",
    "new_data = new_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "except_val=0\n",
    "cid_value = new_data['cid'].to_list()\n",
    "PIC50_value = (-np.log10(new_data['acvalue']*10**-6)).to_list()\n",
    "\n",
    "PIC50_value = pd.DataFrame(PIC50_value,columns = [\"y\"])\n",
    "y_data = PIC50_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WebAPI PubChem\n",
    "\n",
    "link = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/new_link_me/property/MolecularWeight,HeavyAtomCount,XLOGP,Complexity,HBondAcceptorCount,MonoisotopicMass,RotatableBondCount,TPSA/CSV\"\n",
    "link_fixed = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/new_link_me/property/MolecularWeight,HeavyAtomCount,XLOGP,Complexity,HBondAcceptorCount,MonoisotopicMass,RotatableBondCount,TPSA/CSV\"\n",
    "sub_link = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/fastsimilarity_2d/cid/replaceme/cids/TXT\"\n",
    "sub_link_fixed = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/fastsimilarity_2d/cid/replaceme/cids/TXT\"\n",
    "#the link with the required properties.\n",
    "counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame = pd.DataFrame()\n",
    "x_data = pd.DataFrame()\n",
    "cid_main_counter=0 \n",
    "for x in cid_value:\n",
    "    for iter_x in range(1000):\n",
    "        try:    \n",
    "            link = link_fixed\n",
    "            link = link.replace(\"new_link_me\",str(x))\n",
    "            data1 = pd.read_csv(link)\n",
    "            data1 = pd.DataFrame(data1)\n",
    "            x_data = x_data.append(data1)\n",
    "            data1 = 0\n",
    "        except Exception as e:\n",
    "            print(\"Exception Encountered as {} .! , Trying again !Iteration : {}\".format(str(e),str(iter_x)))\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        print(\"Something Wrong with the Trials ! Restart The Algorithm!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_saved = x_data\n",
    "x_data = x_data_saved\n",
    "n_cid=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20 sec Wait_time\n",
    "for i in cid_value:\n",
    "    max_tries = 10\n",
    "    \n",
    "    for iter_ in range(max_tries):\n",
    "        try:\n",
    "            #print(\"inside Try\")\n",
    "            #time.sleep(5)\n",
    "\n",
    "\n",
    "            link = link_fixed\n",
    "            link = link.replace(\"new_link_me\",str(i))\n",
    "            f_data = pd.read_csv(link) \n",
    "            \n",
    "            sub_link = sub_link_fixed\n",
    "            sub_link = sub_link.replace(\"replaceme\",str(i))\n",
    "            res = urllib.request.urlopen(sub_link)\n",
    "            data_sub = res.read()\n",
    "            data_sub = str(data_sub)\n",
    "            data_sub = data_sub.replace(\"\\\\n\",\",\") ; data_sub = data_sub.replace('b',\" \")\n",
    "            data_sub = data_sub.replace(\"'\",\"\"); data_sub = data_sub.replace(\" \",\"\")\n",
    "            n_count_loop = 0 \n",
    "            #time.sleep(3)\n",
    "            #print(\"Going for the loop\")\n",
    "            for j in data_sub.split(\",\"):\n",
    "                n_count_loop+=1\n",
    "                if(len(j)>1):\n",
    "                    if(n_count_loop<=30):\n",
    "                        n_cid.append(j)\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    pass\n",
    "             \n",
    "        except:\n",
    "            if(except_val>=15):\n",
    "                break\n",
    "            else:\n",
    "                print(\"Re-Trying\")\n",
    "                except_val+=1\n",
    "                #time.sleep(3)\n",
    "                continue\n",
    "        else:\n",
    "            break\n",
    "    '''else:\n",
    "        print(\"Either The Network is Down(So no point in continuing ) , Or Some Uknown Error Spotted!. Refer Error Code , Continuing with Fetched Data\")\n",
    "        time.sleep(5)\n",
    "        break'''\n",
    "    \n",
    "    \n",
    "    '''final_data_frame = final_data_frame.append(f_data)\n",
    "    cid_main_counter+=1\n",
    "    final_data_frame.to_csv(\"fdf1.csv\")\n",
    "         \n",
    "   \n",
    "\n",
    "    print(\"Main cid no: {}\".format(cid_main_counter))\n",
    "    #time.sleep(5)'''\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_count = 0\n",
    "t_count = 0\n",
    "phase_count=0\n",
    "f_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data mining PubChem through web API\n",
    "\n",
    "for k in n_cid:\n",
    "    k_count+=1\n",
    "    t_count+=1\n",
    "    phase_count+=1\n",
    "    for sub_iter in range(10):\n",
    "            try:\n",
    "                if(t_count>=50):\n",
    "                    #print(\"taking Rest\")\n",
    "                    time.sleep(15)\n",
    "                    t_count=0\n",
    "                    \n",
    "                #print(\"Inside Try\"+str(k_count))\n",
    "            \n",
    "                link = link_fixed\n",
    "                link = link.replace(\"new_link_me\",str(k))\n",
    "                #print(\"replacement done\"+str(k_count))\n",
    "                f_data_df = pd.read_csv(link)\n",
    "                f_data = f_data.append(f_data_df)\n",
    "                print(\"Passed Without Exception\"+str(k_count))\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(str(e) + \"Encountered , Please Wait :+ \"+str(k_count))\n",
    "                time.sleep(20)\n",
    "                continue\n",
    "\n",
    "    final_data_frame = final_data_frame.append(f_data)\n",
    "    cid_main_counter+=1\n",
    "    final_data_frame.to_csv(\"fdf1.csv\")\n",
    "    print(\"Data Fetching Continued\"+ str(k_count))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame.drop_duplicates(inplace=True)\n",
    "print(final_data_frame.shape)\n",
    "print(\"The Final Training DataSet: X_data = {} , Y_data = {}\".format(x_data.shape,y_data.shape))\n",
    "print(\"The Final Data For Preditcion is : {}\".format(final_data_frame.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    final_data_frame.reset_index(inplace=True)\n",
    "    final_data_frame.drop('index',axis=1,inplace=True)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame_reset = final_data_frame\n",
    "x_data_reset = x_data\n",
    "y_data_reset = y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto QSAR algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#RUN TO RESET ONLY : TESTING CAUTION\n",
    "final_data_frame = final_data_frame_reset\n",
    "x_data = x_data_reset\n",
    "y_data = y_data_reset'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation for QSAR model building\n",
    "x_data = pd.DataFrame(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.DataFrame(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X :- \"+str(x_data.shape)+\" Y :- \"+str(y_data.shape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = pd.DataFrame()\n",
    "x_data = x_data.astype(\"float64\")\n",
    "y_data = y_data.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#molecular features for AutoQSAR model building\n",
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimental inhibition value for model building\n",
    "y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = y_data['y'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file  = x_data\n",
    "train_file['y'] = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_reg_list=train_file['CID'].to_list()\n",
    "train_file.drop('CID',axis=1,inplace =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_file.isnull().any():\n",
    "    if x == True:\n",
    "        train_file = train_file.fillna(method='ffill')\n",
    "train_file\n",
    "\n",
    "#data set of molecular features and experimental inhibition value for QSAR model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(train_file.columns)\n",
    "x = x[:-1]\n",
    "\n",
    "x_ = train_file[x].values\n",
    "y_ = train_file['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file.describe()\n",
    "x_ = x_.astype(\"float64\")\n",
    "y_ = y_.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size=0.1, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AutoQSAR workflow\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "degree=1\n",
    "polyreg_scaled=make_pipeline(PolynomialFeatures(degree),scaler,LinearRegression())\n",
    "polyreg_scaled.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 Score\n",
    "y_pred = polyreg_scaled.predict(X_test)\n",
    "main_r2 = r2_score(y_test, y_pred, multioutput='uniform_average')\n",
    "max_ = main_r2 \n",
    "max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "comb_list = [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating combinations , function\n",
    "def sub(arr,r):\n",
    "    global comb_list\n",
    "    for i in r:\n",
    "        comb = list(combinations(arr,i))\n",
    "        comb_list.append(comb)\n",
    "    return comb_list\n",
    "newone = 0\n",
    "newone = sub(x , [2,3,4,5,6])\n",
    "del newone[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QSAR model building based on linear multivariate regression for all possible combinations of descriptors and choosing the model with best statistical quality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree 1 \n",
    "coef_dict  = 0\n",
    "loop_index = 0\n",
    "coef_dict = [[]]\n",
    "r2_score_new =[]\n",
    "max_r2 = []\n",
    "index_r2 =[]\n",
    "for i in range(0,len(newone)):\n",
    "    \n",
    "    index_r=0\n",
    "    for combi_ in newone[loop_index]:\n",
    "        \n",
    "        #print(combi_)\n",
    "        features = list(combi_)\n",
    "        features_=train_file[features].values\n",
    "        output_=train_file['y'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_, output_, test_size=0.1, random_state=0)\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        degree=1\n",
    "        polyreg_scaled=make_pipeline(PolynomialFeatures(degree),scaler,LinearRegression())\n",
    "        polyreg_scaled.fit(X_train,y_train)\n",
    "        y_pred = polyreg_scaled.predict(X_test)\n",
    "        r2_score_  = r2_score(y_test, y_pred, multioutput='uniform_average')\n",
    "        r2_score_new.append(r2_score_)\n",
    "    loop_index+=1\n",
    "        \n",
    "    \n",
    "    max_r2.append(max(r2_score_new))\n",
    "    index_r = r2_score_new.index(max(r2_score_new))\n",
    "    index_r2.append(index_r)\n",
    "    r2_score_new =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the best value so far using the regressor\n",
    "sec_index = max_r2.index(max(max_r2))\n",
    "fir_index = index_r2[sec_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if main_r2 > max(max_r2):\n",
    "    r2_features = x\n",
    "else:\n",
    "    \n",
    "    features  = newone[sec_index][fir_index]\n",
    "    maxi_r2 = max(max_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 - degree1 = \" + str(maxi_r2)+str(\"\\n\")+str(\"Features = \")+str(features))\n",
    "reg_max_r2 = max(max_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have the best degree 1 model\n",
    "model_dict = {}\n",
    "model_dict[1]=[maxi_r2,features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_file.isnull().any():\n",
    "    if x == True:\n",
    "        train_file = train_file.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QSAR model building based on non-linear multivariate regression(degree 2) for all possible combinations of descriptors and choosing the model with best statistical quality \n",
    "coef_dict  = 0\n",
    "loop_index = 0\n",
    "coef_dict = [[]]\n",
    "r2_score_new =[]\n",
    "max_r2 = []\n",
    "index_r2 =[]\n",
    "for i in range(0,len(newone)):\n",
    "    \n",
    "    index_r=0\n",
    "    for combi_ in newone[loop_index]:\n",
    "        \n",
    "        #print(combi_)\n",
    "        features = list(combi_)\n",
    "        features_=train_file[features].values\n",
    "        output_=train_file['y'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_, output_, test_size=0.1, random_state=0)\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        degree=2\n",
    "        polyreg_scaled=make_pipeline(PolynomialFeatures(degree),scaler,LinearRegression())\n",
    "        polyreg_scaled.fit(X_train,y_train)\n",
    "        y_pred = polyreg_scaled.predict(X_test)\n",
    "        r2_score_  = r2_score(y_test, y_pred, multioutput='uniform_average')\n",
    "        r2_score_new.append(r2_score_)\n",
    "    loop_index+=1\n",
    "        \n",
    "    \n",
    "    max_r2.append(max(r2_score_new))\n",
    "    index_r = r2_score_new.index(max(r2_score_new))\n",
    "    index_r2.append(index_r)\n",
    "    r2_score_new =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the best value so far using the regressor\n",
    "sec_index = max_r2.index(max(max_r2))\n",
    "fir_index = index_r2[sec_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if main_r2 > max(max_r2):\n",
    "    r2_features = x\n",
    "else:\n",
    "    \n",
    "    features  = newone[sec_index][fir_index]\n",
    "    maxi_r2 = max(max_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 - degree2 = \" + str(maxi_r2)+str(\"\\n\")+str(\"Features = \")+str(features))\n",
    "reg_max_r2 = max(max_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[2]=[maxi_r2,features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_file.isnull().any():\n",
    "    if x == True:\n",
    "        train_file = train_file.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QSAR model building based on non-linear multivariate regression(degree 3) for all possible combinations of descriptors and choosing the model with best statistical quality \n",
    "\n",
    "Data mining from PubChem\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import urllib\n",
    "\n",
    "import os \n",
    "\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import seaborn as seabornInstance \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "import time\n",
    "\n",
    "link1 = \"https://pubchem.ncbi.nlm.nih.gov/sdq/sdqagent.cgi?infmt=json&outfmt=csv&query={%22download%22:%22*%22,%22collection%22:%22bioactivity%22,%22where%22:{%22ands%22:[{%22protacxn%22:%22notnull%22},{%22cid%22:%22notnull%22},{%22repacxn%22:%22P0C6U8%22}]},%22order%22:[%22activity,asc%22],%22start%22:1,%22limit%22:10000000,%22downloadfilename%22:%22PROTACXN_P0C6U8_bioactivity_protein%22}\"\n",
    "\n",
    "for i in range(0,2):\n",
    "\n",
    "    try:\n",
    "\n",
    "        os.remove('downloaded1.csv')\n",
    "\n",
    "        #print(\"Deleted old File\")\n",
    "\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        #print(\"No file \")\n",
    "\n",
    "        break\n",
    "\n",
    "    else:\n",
    "\n",
    "        break\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    try:\n",
    "\n",
    "        data = pd.read_csv(link1)\n",
    "\n",
    "        break\n",
    "\n",
    "    #except IncompleteRead as I:\n",
    "\n",
    "     #   print(\"Server Overloading , Proceeding\")\n",
    "\n",
    "      #  break\n",
    "\n",
    "    except Exception as a:\n",
    "\n",
    "        print(str(a)+\" is the error , Trying {} time\".format(i))\n",
    "\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "\n",
    "        break\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"something Wrong , Try running Again [refer error code for more]\")\n",
    "\n",
    "#data = pd.read_csv(\"downloaded1.csv\",error_bad_lines=False)\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "data\n",
    "\n",
    "\tbaid \tactivity \taid \tsid \tmid \tcid \tgeneid \ttaxid \tpmid \taidtype \t... \tacname \tacvalue \taidsrcname \taidname \tcmpdname \ttargetname \ttargeturl \tdois \tecs \trepacxn\n",
    "0 \t98754968 \tActive \t241511 \t103458247 \t0 \t11667869 \tNaN \t227859 \t15896959 \tConfirmatory \t... \tIC50 \t0.98 \tChEMBL \tIn vitro inhibitory concentration SARS coronav... \t1-Benzo[b]thiophen-2-ylmethyl-7-bromo-1H-indol... \tReplicase polyprotein 1a (SARS coronavirus) \t/protein/P0C6U8 \t10.1016/j.bmcl.2005.04.027 \t3.4.19.12,3.4.22.-,3.4.22.69 \tP0C6U8\n",
    "1 \t98758767 \tActive \t241749 \t103458062 \t0 \t44398002 \tNaN \t227859 \t15896959 \tConfirmatory \t... \tIC50 \t9.40 \tChEMBL \tIn vitro inhibitory concentration against SARS... \t1-(2-Chloro-4-fluoro-benzyl)-5-iodo-1H-indole-... \tReplicase polyprotein 1a (SARS coronavirus) \t/protein/P0C6U8 \t10.1016/j.bmcl.2005.04.027 \t3.4.19.12,3.4.22.-,3.4.22.69 \tP0C6U8\n",
    "2 \t98758768 \tActive \t241749 \t103458580 \t0 \t44398207 \tNaN \t227859 \t15896959 \tConfirmatory \t... \tIC50 \t4.82 \tChEMBL \tIn vitro inhibitory concentration against SARS... \t1-Benzo[b]thiophen-2-ylmethyl-5-fluoro-1H-indo... \tReplicase polyprotein 1a (SARS coronavirus) \t/protein/P0C6U8 \t10.1016/j.bmcl.2005.04.027 \t3.4.19.12,3.4.22.-,3.4.22.69 \tP0C6U8\n",
    "3 \t98758769 \tActive \t241749 \t103458848 \t0 \t44398343 \tNaN \t227859 \t15896959 \tConfirmatory \t... \tIC50 \t2.00 \tChEMBL \tIn vitro inhibitory concentration against SARS... \t1-Benzo[b]thiophen-2-ylmethyl-7-nitro-1H-indol... \tReplicase polyprotein 1a (SARS coronavirus) \t/protein/P0C6U8 \t10.1016/j.bmcl.2005.04.027 \t3.4.19.12,3.4.22.-,3.4.22.69 \tP0C6U8\n",
    "4 \t98758770 \tActive \t241749 \t103459046 \t0 \t44398436 \tNaN \t227859 \t15896959 \tConfirmatory \t... \tIC50 \t17.50 \tChEMBL \tIn vitro inhibitory concentration against SARS... \t5-Iodo-1-[[5-(piperidine-1-carbonyl)thiophen-2... \tReplicase polyprotein 1a (SARS coronavirus) \t/protein/P0C6U8 \t10.1016/j.bmcl.2005.04.027 \t3.4.19.12,3.4.22.-,3.4.22.69 \tP0C6U8\n",
    "... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t... \t...\n",
    "336 \t424668663 \tUnspecified \t688306 \t163312872 \t0 \t14610613 \tNaN \t227859 \t22884354 \tLiterature-derived \t... \tNaN \tNaN \tChEMBL \tTime dependent inhibition of SARS-CoV PLpro ex... \tMethyl tanshinonate \tReplicase polyprotein 1a (SARS coronavirus) \t/protein/P0C6U8 \t10.1016/j.bmc.2012.07.038 \t3.4.19.12,3.4.22.-,3.4.22.69 \tP0C6U8\n",
    "337 \t424668664 \tUnspecified \t688306 \t103456666 \t0 \t164676 \tNaN \t227859 \t22884354 \tLiterature-derived \t... \tNaN \tNaN \tChEMBL \tTime dependent inhibition of SARS-CoV PLpro ex... \t\n",
    "coef_dict  = 0\n",
    "loop_index = 0\n",
    "coef_dict = [[]]\n",
    "r2_score_new =[]\n",
    "max_r2 = []\n",
    "index_r2 =[]\n",
    "for i in range(0,len(newone)):\n",
    "    \n",
    "    index_r=0\n",
    "    for combi_ in newone[loop_index]:\n",
    "        \n",
    "        #print(combi_)\n",
    "        features = list(combi_)\n",
    "        features_=train_file[features].values\n",
    "        output_=train_file['y'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_, output_, test_size=0.1, random_state=0)\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        degree=3\n",
    "        polyreg_scaled=make_pipeline(PolynomialFeatures(degree),scaler,LinearRegression())\n",
    "        polyreg_scaled.fit(X_train,y_train)\n",
    "        y_pred = polyreg_scaled.predict(X_test)\n",
    "        r2_score_  = r2_score(y_test, y_pred, multioutput='uniform_average')\n",
    "        r2_score_new.append(r2_score_)\n",
    "    loop_index+=1\n",
    "        \n",
    "    \n",
    "    max_r2.append(max(r2_score_new))\n",
    "    index_r = r2_score_new.index(max(r2_score_new))\n",
    "    index_r2.append(index_r)\n",
    "    r2_score_new =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the best value so far using the regressor\n",
    "sec_index = max_r2.index(max(max_r2))\n",
    "fir_index = index_r2[sec_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if main_r2 > max(max_r2):\n",
    "    r2_features = x\n",
    "else:\n",
    "    \n",
    "    features  = newone[sec_index][fir_index]\n",
    "    maxi_r2 = max(max_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 - degree3 = \" + str(maxi_r2)+str(\"\\n\")+str(\"Features = \")+str(features))\n",
    "reg_max_r2 = max(max_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[3]=[maxi_r2,features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_file.isnull().any():\n",
    "    if x == True:\n",
    "        train_file = train_file.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cid_mix_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction with the validated model\n",
    "model_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(model_dict[1][1])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trained =train_file[features].values\n",
    "y_trained = train_file['y'].values\n",
    "x_trained.shape,y_trained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_trained, y_trained, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly regression - degree 1\n",
    "scaler = preprocessing.StandardScaler()\n",
    "degree=1\n",
    "polyreg_scaled=make_pipeline(PolynomialFeatures(degree),scaler,LinearRegression())\n",
    "polyreg_scaled.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 Score\n",
    "y_pred = polyreg_scaled.predict(X_test)\n",
    "r2_score(y_test, y_pred, multioutput='uniform_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frameF1 = final_data_frame[final_data_frame['MolecularWeight'] <= 500]\n",
    "final_data_frameF2 = final_data_frameF1[final_data_frameF1['XLogP'] <=5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data_cid = final_data_frameF2[\"CID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features.append('CID')\n",
    "new_features = features.append(\"CID\")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame1 = final_data_frameF2[features]\n",
    "for x in final_data_frame1.isnull().any():\n",
    "    if x == True:\n",
    "        final_data_frame1 = final_data_frame1.fillna(method='ffill')\n",
    "final_data_frame1.drop(columns='CID',inplace=True)\n",
    "final_data_frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_1 = polyreg_scaled.predict(final_data_frame1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_1 = list(final_pred_1)\n",
    "final_data_frame1['CID'] = pred_data_cid\n",
    "final_data_frame1['y_'] = final_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_final_data_frame1 = final_data_frame1\n",
    "sorted_final_df = final_data_frame1.sort_values('y_',ascending =0)\n",
    "final_larg= sorted_final_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_larg = final_larg[['CID','y_']]\n",
    "top_cid = final_larg[\"CID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Top 50 Drug Leads Which are identified with PubChem cid's are (USING Linear REGRESSION): \")\n",
    "itter_count = 0\n",
    "for itter in top_cid:\n",
    "    itter_count+=1\n",
    "    \n",
    "    print(str(itter_count)+\" : \"+str(itter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"r2 = \"+str(r2_score(y_test, y_pred, multioutput='uniform_average')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cid_mix_df['Degree 1'] = top_cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cid_1 = pd.DataFrame()\n",
    "final_cid_1['CID'] = top_cid\n",
    "final_cid_1.to_csv(\"final_cid_degree_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(model_dict[2][1])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trained =train_file[features].values\n",
    "y_trained = train_file['y'].values\n",
    "x_trained.shape,y_trained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_trained, y_trained, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly regression - degree 2\n",
    "scaler = preprocessing.StandardScaler()\n",
    "degree=2\n",
    "polyreg_scaled=make_pipeline(PolynomialFeatures(degree),scaler,LinearRegression())\n",
    "polyreg_scaled.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 Score\n",
    "y_pred = polyreg_scaled.predict(X_test)\n",
    "r2_score(y_test, y_pred, multioutput='uniform_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frameF1 = final_data_frame[final_data_frame['MolecularWeight'] <= 500]\n",
    "final_data_frameF2 = final_data_frameF1[final_data_frameF1['XLogP'] <=5.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data_cid = final_data_frameF2[\"CID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features.append('CID')\n",
    "new_features = features.append(\"CID\")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame1 = final_data_frameF2[features]\n",
    "for x in final_data_frame1.isnull().any():\n",
    "    if x == True:\n",
    "        final_data_frame1 = final_data_frame1.fillna(method='ffill')\n",
    "final_data_frame1.drop(columns='CID',inplace=True)\n",
    "final_data_frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_1 = polyreg_scaled.predict(final_data_frame1)\n",
    "final_pred_1 = list(final_pred_1)\n",
    "final_data_frame1['CID'] = pred_data_cid\n",
    "final_data_frame1['y_'] = final_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_final_data_frame1 = final_data_frame1\n",
    "sorted_final_df = final_data_frame1.sort_values('y_',ascending =0)\n",
    "final_larg= sorted_final_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_larg = final_larg[['CID','y_']]\n",
    "top_cid = final_larg[\"CID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Top 50 Drug Leads Which are identified with PubChem cid's are (USING DEGREE 2 REGRESSION): \")\n",
    "itter_count = 0\n",
    "for itter in top_cid:\n",
    "    itter_count+=1\n",
    "    \n",
    "    print(str(itter_count)+\" : \"+str(itter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cid_mix_df['Degree 2'] = top_cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"r2 = \"+str(r2_score(y_test, y_pred, multioutput='uniform_average')))\n",
    "final_cid_2 = pd.DataFrame()\n",
    "final_cid_2['CID'] = top_cid\n",
    "final_cid_2.to_csv(\"final_cid_degree_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(model_dict[3][1])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trained =train_file[features].values\n",
    "y_trained = train_file['y'].values\n",
    "x_trained.shape,y_trained.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_trained, y_trained, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly regression - degree 3\n",
    "scaler = preprocessing.StandardScaler()\n",
    "degree=3\n",
    "polyreg_scaled=make_pipeline(PolynomialFeatures(degree),scaler,LinearRegression())\n",
    "polyreg_scaled.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 Score\n",
    "y_pred = polyreg_scaled.predict(X_test)\n",
    "r2_score(y_test, y_pred, multioutput='uniform_average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frameF1 = final_data_frame[final_data_frame['MolecularWeight'] <= 500]\n",
    "final_data_frameF2 = final_data_frameF1[final_data_frameF1['XLogP'] <=5.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data_cid = final_data_frameF2[\"CID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features.append('CID')\n",
    "new_features = features.append(\"CID\")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame1 = final_data_frameF2[features]\n",
    "for x in final_data_frame1.isnull().any():\n",
    "    if x == True:\n",
    "        final_data_frame1 = final_data_frame1.fillna(method='ffill')\n",
    "final_data_frame1.drop(columns='CID',inplace=True)\n",
    "final_data_frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred_1 = polyreg_scaled.predict(final_data_frame1)\n",
    "final_pred_1 = list(final_pred_1)\n",
    "final_data_frame1['CID'] = pred_data_cid\n",
    "final_data_frame1['y_'] = final_pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_final_data_frame1 = final_data_frame1\n",
    "sorted_final_df = final_data_frame1.sort_values('y_',ascending =0)\n",
    "final_larg= sorted_final_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_larg = final_larg[['CID','y_']]\n",
    "top_cid = final_larg[\"CID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Top 50 Drug Leads Which are identified with PubChem cid's are (USING DEGREE 3 REGRESSION): \")\n",
    "itter_count = 0\n",
    "for itter in top_cid:\n",
    "    itter_count+=1\n",
    "    \n",
    "    print(str(itter_count)+\" : \"+str(itter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cid_mix_df['Degree 3'] = top_cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"r2 = \"+str(r2_score(y_test, y_pred, multioutput='uniform_average')))\n",
    "final_cid_2 = pd.DataFrame()\n",
    "final_cid_2['CID'] = top_cid\n",
    "final_cid_2.to_csv(\"final_cid_degree_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " THE END - COMPOUND FETCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cid_mix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cid_mix_df.to_csv(\"TOP_CID_123.csv\")\n",
    "\n",
    "\n",
    "\n",
    "top_cid = top_cid_mix_df['Degree 3']\n",
    "\n",
    "top_cid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated In Silico modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResSelect(Select):\n",
    "    def accept_residue(self, residue):\n",
    "        if is_aa(residue):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "class ProteinPreparer:\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, protein: str, dir: str):\n",
    "        self.protein = protein\n",
    "        self.tmpdir = dir\n",
    "        self.filename = self.tmpdir + '/pdb{}.ent'.format(self.protein)\n",
    "\n",
    "    def prepare_protein(self):\n",
    "        parser = PDBParser()\n",
    "        io = PDBIO()\n",
    "        PDBList().retrieve_pdb_file(pdb_code=self.protein, pdir=self.tmpdir,\n",
    "                                    file_format='pdb')  # saves pdb in a form of ent file\n",
    "        ipdb = parser.get_structure('ipdb', self.filename)  # Input pdb as a self.filename\n",
    "        io.set_structure(ipdb)  # Setting structure for input pdb\n",
    "        io.save(self.tmpdir + '/'+self.protein + '.pdb', ResSelect(),\n",
    "                preserve_atom_numbering=True)  # saves the cleaned pdb\n",
    "        os.system(prepare_protein_path + self.tmpdir + '/{}.pdb'.format(\n",
    "            self.protein))  # prepares the structure by adding polar hydrogens and adding gesteiger charges\n",
    "        shutil.move(self.protein + '.pdbqt', self.tmpdir)\n",
    "\n",
    "prepare_ligand_path = '~/MGLTools-1.5.6/bin/pythonsh ~/MGLTools-1.5.6/MGLToolsPckgs/AutoDockTools/Utilities24/prepare_ligand4.py -A bonds_hydrogens -U nphs_lps -l'\n",
    "\n",
    "class LigandPreparer:\n",
    "\n",
    "    def __init__(self, ligand_file: str, dir: str):\n",
    "        self.ligand = ligand_file\n",
    "        self.tmpdir = dir\n",
    "\n",
    "    def prepare_ligand(self):\n",
    "        url = 'https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{}/SDF'.format(self.ligand)\n",
    "        urllib.request.urlretrieve(url, self.tmpdir + '/{}'.format(self.ligand + '.sdf')) # downloads the file\n",
    "        os.system('obabel {} -O {} --gen3d'.format(\n",
    "            self.tmpdir + '/' + self.ligand + '.sdf', self.tmpdir + '/' + self.ligand + 'prep.pdb')\n",
    "        ) # generates 3d coords\n",
    "        os.system(\n",
    "            'obminimize -ff GAFF {} > {}'.format(\n",
    "                self.tmpdir + '/' + self.ligand + 'prep.pdb', self.tmpdir + '/' + self.ligand + '.pdb'\n",
    "                                                 )\n",
    "        ) # minimizes using GAFF\n",
    "        os.system(prepare_ligand_path + '{}'.format(self.tmpdir + '/' + self.ligand + '.pdb'\n",
    "                                                    )) # adds charges, sets rotatable bonds\n",
    "        shutil.move(self.ligand + '.pdbqt', self.tmpdir)\n",
    "\n",
    "class VinaDocker:\n",
    "\n",
    "    def __init__(self, ligentry: str, protentry: str, protein_pdbqt: str, ligand_pdbqt: str, dir: str):\n",
    "        self.protein = protein_pdbqt + '.pdbqt'\n",
    "        self.protpdb = protentry + '.pdb'\n",
    "        self.protname = os.path.basename(self.protein)\n",
    "        self.ligand = ligand_pdbqt + '.pdbqt'\n",
    "        self.ligname = os.path.basename(self.ligand)\n",
    "        self.tmpdir = dir\n",
    "        # self.docklog = './results/' + protentry + '_' + ligentry + '_docking.log' # !!\n",
    "        # self.dockfile =  './results/' + protentry + '_' + ligentry + '.out' # !!\n",
    "        self.docklog = protentry + '_' + ligentry + '_docking.log' # !!\n",
    "        self.dockfile = protentry + '_' + ligentry + '.out' # !!\n",
    "        self.complex_name = protentry + '_' + ligentry + '_cplx.pdb'\n",
    "\n",
    "    def dock_merge_plip(self):\n",
    "        df = PandasPdb().read_pdb(self.tmpdir + '/' + self.protpdb)  # opens protein to calculate grid\n",
    "        minx = df.df['ATOM']['x_coord'].min()\n",
    "        maxx = df.df['ATOM']['x_coord'].max()\n",
    "        cent_x = round((maxx + minx) / 2, 2)\n",
    "        size_x = round(abs(maxx - minx) + 3, 2)\n",
    "        miny = df.df['ATOM']['y_coord'].min()\n",
    "        maxy = df.df['ATOM']['y_coord'].max()\n",
    "        cent_y = round((maxy + miny) / 2, 2)\n",
    "        size_y = round(abs(maxy - miny) + 3, 2)\n",
    "        minz = df.df['ATOM']['z_coord'].min()\n",
    "        maxz = df.df['ATOM']['z_coord'].max()\n",
    "        cent_z = round((maxz + minz) / 2, 2)\n",
    "        size_z = round(abs(maxz - minz) + 3, 2)\n",
    "        assert (type(cent_x) != None), \"Protein structure is damaged\"\n",
    "        assert (type(cent_y) != None), \"Protein structure is damaged\"\n",
    "        assert (type(cent_z) != None), \"Protein structure is damaged\"\n",
    "\n",
    "\n",
    "        print(\"Center point of docking grid for {} is as follows: \"\n",
    "              \"x: {}, y: {}, z: {}\".format(self.protein, size_x, size_y, size_z))\n",
    "        print(\"Sizes of docking grid are as follows:\"\n",
    "              \"x: {}, y: {}, z: {}\".format(cent_x, cent_y, cent_z))\n",
    "        print(\"Receptor: \", self.protein, \"\\n\", \"Ligand: \", self.ligand, \"\\n\", \"Output file: \", self.dockfile)\n",
    "        os.system(\n",
    "            'vina --receptor {} --ligand \"{}\" --center_x {} --center_y {} --center_z {} --size_x {} --size_y {} --size_z {} --log \"{}\" --out \"{}\"'.format(\n",
    "                self.protein,\n",
    "                self.ligand,\n",
    "                cent_x,\n",
    "                cent_y,\n",
    "                cent_z,\n",
    "                size_x,\n",
    "                size_y,\n",
    "                size_z,\n",
    "                self.docklog,\n",
    "                self.dockfile\n",
    "            ))\n",
    "        \"\"\"Postprocessing of docking files\"\"\"\n",
    "        # time.sleep(60)\n",
    "        df.df['ATOM']['segment_id'].replace(r'.{1,}', '', regex=True, inplace=True) # Clean pdbqt inheritance\n",
    "        df.df['ATOM']['blank_4'].replace(r'.{1,}', '', regex=True, inplace=True)\n",
    "        docking_output_df = PandasPdb().read_pdb(self.dockfile)\n",
    "        docking_output_df.df['HETATM'].drop_duplicates(subset='atom_number', keep='first', inplace=True)  # extract first model\n",
    "        docking_output_df.df['HETATM']['segment_id'].replace(r'.{1,}', '', regex=True, inplace=True)\n",
    "        docking_output_df.df['HETATM']['blank_4'].replace(r'.{1,}', '', regex=True, inplace=True)  # clean pdbqt inheritance\n",
    "        df.df['ATOM'] = df.df['ATOM'].append(docking_output_df.df['HETATM'], ignore_index=True) # merges the files\n",
    "        df.to_pdb(path = self.complex_name,\n",
    "                  records=['ATOM','HETATM'],\n",
    "                  gz = False,\n",
    "                  append_newline=True)\n",
    "        # try:\n",
    "        #     ObtainInteractionsFromComplex(self.complex_name).connect_retrieve() # PLIP analysis\n",
    "        # except:\n",
    "        #     pass\n",
    "        shutil.move(self.complex_name, './results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading PDB structure '1w77'...\n",
      "Center point of docking grid for /home/rmadeye/PycharmProjects/target2drug/tmpahrv5bd0/1w77.pdbqt is as follows: x: 49.39, y: 50.04, z: 53.25\n",
      "Sizes of docking grid are as follows:x: 12.92, y: 64.08, z: -23.53\n",
      "Receptor:  /home/rmadeye/PycharmProjects/target2drug/tmpahrv5bd0/1w77.pdbqt \n",
      " Ligand:  /home/rmadeye/PycharmProjects/target2drug/tmpahrv5bd0/6500.pdbqt \n",
      " Output file:  1w77_6500.out\n",
      "Center point of docking grid for /home/rmadeye/PycharmProjects/target2drug/tmpahrv5bd0/1w77.pdbqt is as follows: x: 49.39, y: 50.04, z: 53.25\n",
      "Sizes of docking grid are as follows:x: 12.92, y: 64.08, z: -23.53\n",
      "Receptor:  /home/rmadeye/PycharmProjects/target2drug/tmpahrv5bd0/1w77.pdbqt \n",
      " Ligand:  /home/rmadeye/PycharmProjects/target2drug/tmpahrv5bd0/6501.pdbqt \n",
      " Output file:  1w77_6501.out\n",
      "Center point of docking grid for /home/rmadeye/PycharmProjects/target2drug/tmpahrv5bd0/1w77.pdbqt is as follows: x: 49.39, y: 50.04, z: 53.25\n",
      "Sizes of docking grid are as follows:x: 12.92, y: 64.08, z: -23.53\n",
      "Receptor:  /home/rmadeye/PycharmProjects/target2drug/tmpahrv5bd0/1w77.pdbqt \n",
      " Ligand:  /home/rmadeye/PycharmProjects/target2drug/tmpahrv5bd0/6502.pdbqt \n",
      " Output file:  1w77_6502.out\n"
     ]
    }
   ],
   "source": [
    "#Dummy CID:\n",
    "# top_cid=['6500', '6501', '6502']\n",
    "\n",
    "# Part 1 - look for PDB entry\n",
    "from Bio import SwissProt\n",
    "import tempfile\n",
    "handle = ExPASy.get_sprot_raw(check_id)\n",
    "record = SwissProt.read(handle)\n",
    "for i in record.cross_references:\n",
    "    if i[0] == 'PDB':\n",
    "        entry_pdb = i[1] # Pick the first one\n",
    "        break\n",
    "#Part 2 - download and prepare PDB\n",
    "prepare_protein_path = '~/MGLTools-1.5.6/bin/pythonsh ~/MGLTools-1.5.6/MGLToolsPckgs/AutoDockTools/Utilities24/prepare_receptor4.py -A bonds_hydrogens -U nphs_lps_waters_nonstdres_deleteAltB -r'\n",
    "with tempfile.TemporaryDirectory(dir=os.getcwd()) as tmpdir:\n",
    "# tmpdir = os.getcwd()+'/testcase'\n",
    "    ProteinPreparer(entry_pdb.lower(), tmpdir).prepare_protein()\n",
    "    #Part 3 - prepare ligands\n",
    "    for CID_entry in top_cid:\n",
    "        LigandPreparer(CID_entry,tmpdir).prepare_ligand()\n",
    "        #Part 4 - dock the ligand\n",
    "        VinaDocker(protentry=entry_pdb.lower(),\n",
    "                            ligentry=CID_entry,\n",
    "                            protein_pdbqt=tmpdir + '/' + entry_pdb.lower(),\n",
    "                            ligand_pdbqt=tmpdir + '/' + CID_entry,\n",
    "                            dir=tmpdir\n",
    "                            ).dock_merge_plip()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Connection successful\n",
      "Processing file ./results/1w77_6502_cplx.pdb\n",
      "https://projects.biotec.tu-dresden.de/plip-web/plip/download/cfe86d9c-9bf6-4f96-8bc4-9264b8ac37f7?filePath=outputs%2F1W77_6502_CPLX_PROTEIN_UNL_Z_1.png\n",
      "Image saved as ./results/1w77_6502_cplx.pdb.png\n",
      "https://projects.biotec.tu-dresden.de/plip-web/plip/download/cfe86d9c-9bf6-4f96-8bc4-9264b8ac37f7?filePath=outputs%2F1W77_6502_CPLX_PROTEIN_UNL_Z_1.pse\n",
      "Pymol sessions saved as ./results/1w77_6502_cplx.pdb.pse\n",
      "Processing file ./results/1w77_6501_cplx.pdb\n",
      "https://projects.biotec.tu-dresden.de/plip-web/plip/download/670e0f14-ee84-487c-89aa-02ef1f782034?filePath=outputs%2F1W77_6501_CPLX_PROTEIN_UNL_Z_1.png\n",
      "Image saved as ./results/1w77_6501_cplx.pdb.png\n",
      "https://projects.biotec.tu-dresden.de/plip-web/plip/download/670e0f14-ee84-487c-89aa-02ef1f782034?filePath=outputs%2F1W77_6501_CPLX_PROTEIN_UNL_Z_1.pse\n",
      "Pymol sessions saved as ./results/1w77_6501_cplx.pdb.pse\n",
      "Processing file ./results/1w77_6500_cplx.pdb\n",
      "https://projects.biotec.tu-dresden.de/plip-web/plip/download/b44bb664-d94a-4b2e-99d7-b4c09ac458c8?filePath=outputs%2F1W77_6500_CPLX_PROTEIN_UNL_Z_1.png\n",
      "Image saved as ./results/1w77_6500_cplx.pdb.png\n",
      "https://projects.biotec.tu-dresden.de/plip-web/plip/download/b44bb664-d94a-4b2e-99d7-b4c09ac458c8?filePath=outputs%2F1W77_6500_CPLX_PROTEIN_UNL_Z_1.pse\n",
      "Pymol sessions saved as ./results/1w77_6500_cplx.pdb.pse\n"
     ]
    }
   ],
   "source": [
    "#Part 5 - PLIP\n",
    "#protein-ligand interaction profiling through PLIP \n",
    "options=Options()\n",
    "options.headless = True\n",
    "plip = webdriver.Firefox(options=options)\n",
    "plip.get(\"https://projects.biotec.tu-dresden.de/plip-web/plip\")\n",
    "print(\"Connection successful\")\n",
    "\n",
    "for cplx in os.listdir('./results/'):\n",
    "    if cplx.endswith('cplx.pdb'):\n",
    "        cplx=f'./results/{cplx}'\n",
    "        print(\"Processing file {}\".format(cplx))\n",
    "    \n",
    "        select_pdb_input = plip.find_element_by_xpath(\"//*[@id='select-pdb-by-file']\").click() \n",
    "\n",
    "        browse = plip.find_element_by_xpath(\n",
    "            '/html/body/div[1]/div[2]/div/form/div[1]/div[1]/div[3]/input'\n",
    "        ).send_keys(                                                       \n",
    "            os.getcwd()+'/{}'.format(cplx)\n",
    "        )\n",
    "\n",
    "        send_file = plip.find_element_by_xpath(\"//*[@id='submit']\").click() \n",
    "        time.sleep(10) \n",
    "        try:\n",
    "            try:\n",
    "                open_interactions_1 = plip.find_element_by_xpath('/html/body/div/div[2]/div/div[1]/h2[2]').click()\n",
    "                open_interactions_2 = plip.find_element_by_xpath('/html/body/div[1]/div[2]/div/div[1]/div[2]/h3').click()\n",
    "                open_interactions_3 = plip.find_element_by_xpath('/html/body/div[1]/div[2]/div/div[1]/div[2]/div/h4').click()\n",
    "                pngs = plip.find_elements_by_xpath(\"//a[contains(@href,'.png')]\")\n",
    "                pymolsessions = plip.find_elements_by_xpath(\"//a[contains(@href,'.pse')]\")\n",
    "                \n",
    "            except:\n",
    "                open_interactions_1 = plip.find_element_by_xpath('/html/body/div[1]/div[2]/div/div[1]/h2[1]').click()\n",
    "                open_interactions_2 = plip.find_element_by_xpath('/html/body/div[1]/div[2]/div/div[1]/div[1]/h3').click()\n",
    "                open_interactions_3 = plip.find_element_by_xpath('/html/body/div[1]/div[2]/div/div[1]/div[1]/div/h4').click()\n",
    "                pngs = plip.find_elements_by_xpath(\"//a[contains(@href,'.png')]\")\n",
    "                pymolsessions = plip.find_elements_by_xpath(\"//a[contains(@href,'.pse')]\")\n",
    "\n",
    "            for image in pngs:\n",
    "                print(image.get_attribute(\"href\"))\n",
    "                output_image = requests.get(image.get_attribute(\"href\"))\n",
    "                open(\n",
    "                    os.getcwd()+'/{}'.format(cplx+'.png'), 'wb'\n",
    "                ).write(output_image.content)\n",
    "                print(\"Image saved as {}\".format(cplx+'.png'))\n",
    "\n",
    "            for pysession in pymolsessions:\n",
    "                print(pysession.get_attribute(\"href\"))\n",
    "                pse = requests.get(pysession.get_attribute(\"href\"))\n",
    "                open(\n",
    "                    os.getcwd()+'/{}'.format(cplx+'.pse'), 'wb'\n",
    "                ).write(pse.content)\n",
    "                print(\"Pymol sessions saved as {}\".format(cplx+'.pse'))\n",
    "                  \n",
    "            restart_plip = plip.find_element_by_xpath('/html/body/div[1]/div[2]/div/p[3]/a').click()\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(\"No interactions found for {} or damaged structure\".format(cplx))\n",
    "            try:\n",
    "                restart_plip = plip.find_element_by_xpath('/html/body/div[1]/div[2]/div/p[3]/a').click()\n",
    "                time.sleep(5)\n",
    "            except:\n",
    "                restart_plip = plip.find_element_by_xpath('/html/body/div[1]/div[2]/div[2]/p/a').click() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROJECT ENDS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}